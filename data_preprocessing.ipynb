{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6057b09c-605c-4c3f-9b5f-3487b3a988f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 0: syntax error near unexpected token `'wordnet''\n",
      "/bin/bash: -c: line 0: `nltk.download('wordnet')'\n"
     ]
    }
   ],
   "source": [
    "# !wget https://huggingface.co/datasets/declare-lab/MELD/resolve/main/MELD.Raw.tar.gz\n",
    "# This file was too big for my computer to handle so I just downloaded the train file directly from the repository. \n",
    "# !pip install nltk\n",
    "!nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330a00d-c9d3-40ec-86ff-b3e1fe3d8b8c",
   "metadata": {},
   "source": [
    "## Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba33d292-df03-45ad-ae50-f1ede7a16b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sindhukothe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import csv\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0aa76220-8c1e-49ed-9614-de768559c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues = pd.read_csv(\"labelled_emotions.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2e3acc12-92c5-4b45-bfd1-db89901742cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No.</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Why do all you’re coffee mugs have numbers on ...</td>\n",
       "      <td>Mark</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>00:14:38,127</td>\n",
       "      <td>00:14:40,378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Oh. That’s so Monica can keep track. That way ...</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>00:14:40,629</td>\n",
       "      <td>00:14:47,385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Y'know what?</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>00:14:56,353</td>\n",
       "      <td>00:14:57,520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>Come on, Lydia, you can do it.</td>\n",
       "      <td>Joey</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0:10:44,769</td>\n",
       "      <td>0:10:46,146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>Push!</td>\n",
       "      <td>Joey</td>\n",
       "      <td>joy</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0:10:46,146</td>\n",
       "      <td>0:10:46,833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr No.                                          Utterance Speaker  \\\n",
       "0       1  Why do all you’re coffee mugs have numbers on ...    Mark   \n",
       "1       2  Oh. That’s so Monica can keep track. That way ...  Rachel   \n",
       "2       3                                       Y'know what?  Rachel   \n",
       "3      19                     Come on, Lydia, you can do it.    Joey   \n",
       "4      20                                              Push!    Joey   \n",
       "\n",
       "    Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "0  surprise  positive            0             0       3       19   \n",
       "1     anger  negative            0             1       3       19   \n",
       "2   neutral   neutral            0             2       3       19   \n",
       "3   neutral   neutral            1             0       1       23   \n",
       "4       joy  positive            1             1       1       23   \n",
       "\n",
       "      StartTime       EndTime  \n",
       "0  00:14:38,127  00:14:40,378  \n",
       "1  00:14:40,629  00:14:47,385  \n",
       "2  00:14:56,353  00:14:57,520  \n",
       "3   0:10:44,769   0:10:46,146  \n",
       "4   0:10:46,146   0:10:46,833  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10caca53-9ad2-4cb3-a25b-0d14a15143e8",
   "metadata": {},
   "source": [
    "## This section is to split the dialougues on the basis of emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7241dcd1-996d-42e5-b8cf-7998f58fcb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['surprise', 'anger', 'neutral', 'joy', 'sadness', 'fear',\n",
       "       'disgust'], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogues[\"Emotion\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d7b277e8-bea0-4ff0-b210-32568c8fcf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists: Emotions/anger.csv\n",
      "Already exists: Emotions/disgust.csv\n",
      "Already exists: Emotions/fear.csv\n",
      "Already exists: Emotions/joy.csv\n",
      "Already exists: Emotions/sadness.csv\n",
      "Already exists: Emotions/surprise.csv\n",
      "Already exists: Emotions/neutral.csv\n"
     ]
    }
   ],
   "source": [
    "# List of emotions\n",
    "emotions = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"neutral\"]\n",
    "\n",
    "# Ensure the folder exists\n",
    "os.makedirs(\"Emotions\", exist_ok=True)\n",
    "\n",
    "# Create a CSV file for each emotion with sample headers\n",
    "for emotion in emotions:\n",
    "    file_path = f\"Emotions/{emotion}.csv\"\n",
    "    \n",
    "    # Only create the file if it doesn't already exist\n",
    "    if not os.path.exists(file_path):\n",
    "        # Create a basic DataFrame structure\n",
    "        df = pd.DataFrame(columns=[\"dialogue\", \"sentiment\"])\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"Created: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Already exists: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a655b205-1db9-4049-9a2f-7e5aedc14822",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dialogues.iterrows():\n",
    "    new_row = [row[\"Utterance\"], row[\"Sentiment\"]]\n",
    "    # print(new_row)\n",
    "    fname = \"Emotions/\" + row[\"Emotion\"] + \".csv\"\n",
    "    with open(fname, \"a\", newline=\"\") as f:  \n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2fd7b2-ff14-484d-87ad-448acaf8853e",
   "metadata": {},
   "source": [
    "## This section is to split dialogues on the basis of VAD scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3b3aa24d-bea6-47e4-9489-5f270fc50400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caches for the VAD scores so that we would not have to iterate through the entire df everytime we need something\n",
    "val_cache = {}\n",
    "ar_cache = {}\n",
    "dom_cache = {}\n",
    "\n",
    "#lemmatizer for words that are not in the csv file\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f57e16-a9de-4c37-8877-ee0d31628433",
   "metadata": {},
   "source": [
    "### Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "853f4751-a318-45b1-8d98-887992826887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    44728.000000\n",
       "mean        -0.002367\n",
       "std          0.500050\n",
       "min         -1.000000\n",
       "25%         -0.376000\n",
       "50%          0.000000\n",
       "75%          0.375000\n",
       "max          1.000000\n",
       "Name: valence, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valence = pd.read_csv(\"VAD_lexicon/valence.txt\", sep=\"\\t\",) \n",
    "valence[\"valence\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f960ec2e-dcc5-409e-afd5-13e0f949030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val(str):\n",
    "    words = str.split(\" \")\n",
    "    val_score = 0\n",
    "    for word in words:\n",
    "        word = word.lower() # making the case the same to increase the chances of running into the word\n",
    "        word = word.translate(str.maketrans('', '', string.punctuation)) #removing punctuation \n",
    "        if word not in val_cache.keys():\n",
    "            word_valence = valence.loc[valence[\"term\"] == word, \"valence\"]\n",
    "            if len(word_valence) > 0:\n",
    "                score = word_valence.values[0]\n",
    "                val_cache[word] = score  # Cache the result\n",
    "                val_score += score\n",
    "            else:\n",
    "                lemma = lemmatizer.lemmatize(word)\n",
    "                if lemma != word:  # sometimes the word and the lemma are the same, \n",
    "                                         # in which case there isnt really a point in wasting time on the\n",
    "                    if lemma in val_cache.keys():\n",
    "                        val_score += val_cache[lemma]\n",
    "                    else:\n",
    "                        lemma_valence = valence.loc[valence[\"term\"] == lemma, \"valence\"]\n",
    "                        if len(lemma_valence) > 0:\n",
    "                            score = lemma_valence.values[0]\n",
    "                            val_cache[lemma] = score  \n",
    "                            val_score += score\n",
    "                        else:\n",
    "                            val_cache[word] = 0\n",
    "        else:\n",
    "            val_score += val_cache[word]\n",
    "\n",
    "    return val_score / len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f83747ba-c928-4c10-baa3-5748c87e0595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: val_0-1.csv\n",
      "Created: val_-1-0.csv\n"
     ]
    }
   ],
   "source": [
    "# List of ranges\n",
    "ranges = [\"0-1\", \"-1-0\"]\n",
    "\n",
    "# Ensure the folder exists\n",
    "# os.makedirs(\"Valence\", exist_ok=True)\n",
    "\n",
    "for r in ranges:\n",
    "    file_path = f\"val_{r}.csv\"\n",
    "    val = get_val\n",
    "    # Only create the file if it doesn't already exist\n",
    "    if not os.path.exists(file_path):\n",
    "        # Create a basic DataFrame structure\n",
    "        df = pd.DataFrame(columns=[\"Utterance\", \"Emotion\", \"Sentiment\", \"Valence\"])\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"Created: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Already exists: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "17036d27-ca84-4ecd-a82b-8297fb3608fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dialogues.iterrows():\n",
    "    val = get_val(row[\"Utterance\"])\n",
    "    new_row = [row[\"Utterance\"], row[\"Emotion\"], row[\"Sentiment\"], val]\n",
    "    v_cat = \"\"\n",
    "    \n",
    "    if val > 0.0:\n",
    "        v_cat = \"0-1\"\n",
    "    else:\n",
    "        v_cat = \"-1-0\"\n",
    "    \n",
    "    fname = \"val_\" + v_cat + \".csv\"\n",
    "    with open(fname, \"a\", newline=\"\") as f:  \n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "242ad37f-bec6-4e5f-8419-6326fd61deb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in ranges:\n",
    "    fname = \"val_\" + r + \".csv\"\n",
    "    df = pd.read_csv(fname)\n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    df_cleaned.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0b50d3fd-cce7-45c3-91b0-1504f414d2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why do all you’re coffee mugs have numbers on ...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.111818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oh. That’s so Monica can keep track. That way ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.055364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Come on, Lydia, you can do it.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.103143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let's get that ball and really move, hey, hey,...</td>\n",
       "      <td>joy</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.119818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Let's—  I was just—yeah, right.</td>\n",
       "      <td>joy</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Utterance   Emotion Sentiment  \\\n",
       "0  Why do all you’re coffee mugs have numbers on ...  surprise  positive   \n",
       "1  Oh. That’s so Monica can keep track. That way ...     anger  negative   \n",
       "2                     Come on, Lydia, you can do it.   neutral   neutral   \n",
       "3  Let's get that ball and really move, hey, hey,...       joy  positive   \n",
       "4                    Let's—  I was just—yeah, right.       joy  positive   \n",
       "\n",
       "    Valence  \n",
       "0  0.111818  \n",
       "1  0.055364  \n",
       "2  0.103143  \n",
       "3  0.119818  \n",
       "4  0.080000  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"val_0-1.csv\") \n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ac2dc-9fa3-4d3b-940c-8115dd09f4d0",
   "metadata": {},
   "source": [
    "### Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "30d6addb-6e01-4ba4-82b3-363bb311d365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    44728.000000\n",
       "mean         0.022224\n",
       "std          0.504393\n",
       "min         -1.000000\n",
       "25%         -0.362500\n",
       "50%          0.000000\n",
       "75%          0.500000\n",
       "max          1.000000\n",
       "Name: arousal, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arousal = pd.read_csv(\"VAD_lexicon/arousal.txt\", sep=\"\\t\",) \n",
    "arousal[\"arousal\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f9ad88e6-d652-4944-aba8-e9d4ac2d8011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ar(str):\n",
    "    words = str.split(\" \")\n",
    "    ar_score = 0\n",
    "    for word in words:\n",
    "        word = word.lower() # making the case the same to increase the chances of running into the word\n",
    "        word = word.translate(str.maketrans('', '', string.punctuation)) #removing punctuation \n",
    "        if word not in ar_cache.keys():\n",
    "            word_ar = arousal.loc[arousal[\"term\"] == word, \"arousal\"]\n",
    "            if len(word_ar) > 0:\n",
    "                score = word_ar.values[0]\n",
    "                ar_cache[word] = score  # Cache the result\n",
    "                ar_score += score\n",
    "            else:\n",
    "                lemma = lemmatizer.lemmatize(word)\n",
    "                if lemma != word:  # sometimes the word and the lemma are the same, \n",
    "                                         # in which case there isnt really a point in wasting time on the\n",
    "                    if lemma in ar_cache.keys():\n",
    "                        ar_score += ar_cache[lemma]\n",
    "                    else:\n",
    "                        lemma_ar = arousal.loc[arousal[\"term\"] == lemma, \"arousal\"]\n",
    "                        if len(lemma_ar) > 0:\n",
    "                            score = lemma_ar.values[0]\n",
    "                            ar_cache[lemma] = score  \n",
    "                            ar_score += score\n",
    "                        else:\n",
    "                            ar_cache[word] = 0\n",
    "        else:\n",
    "            ar_score += ar_cache[word]\n",
    "\n",
    "    return ar_score / len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3d1cfeff-ca2f-47a5-a72f-ef0d989cf223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: ar_0-1.csv\n",
      "Created: ar_-1-0.csv\n"
     ]
    }
   ],
   "source": [
    "# List of ranges\n",
    "ranges = [\"0-1\", \"-1-0\"]\n",
    "\n",
    "# Ensure the folder exists\n",
    "# os.makedirs(\"Valence\", exist_ok=True)\n",
    "\n",
    "for r in ranges:\n",
    "    file_path = f\"ar_{r}.csv\"\n",
    "    val = get_val\n",
    "    # Only create the file if it doesn't already exist\n",
    "    if not os.path.exists(file_path):\n",
    "        # Create a basic DataFrame structure\n",
    "        df = pd.DataFrame(columns=[\"Utterance\", \"Emotion\", \"Sentiment\",\"Arousal\"])\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"Created: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Already exists: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9643d290-eb76-4ebe-a7f2-a2fa1f6f1ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dialogues.iterrows():\n",
    "    ar = get_ar(row[\"Utterance\"])\n",
    "    new_row = [row[\"Utterance\"], row[\"Emotion\"], row[\"Sentiment\"], ar]\n",
    "    \n",
    "    a_cat = \"\"\n",
    "    \n",
    "    if ar > 0.0:\n",
    "        ar_cat = \"0-1\"\n",
    "    else:\n",
    "        ar_cat = \"-1-0\"\n",
    "        # print(row[\"Utterance\"])\n",
    "    \n",
    "    fname = \"ar_\" + ar_cat + \".csv\"\n",
    "    with open(fname, \"a\", newline=\"\") as f:  \n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "34ccc0a9-db5f-424b-b787-7896946f0eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in ranges:\n",
    "    fname = \"ar_\" + r + \".csv\"\n",
    "    df = pd.read_csv(fname)\n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    df_cleaned.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e1e2e514-cb89-49eb-bf4d-c6aa3f2cc780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why do all you’re coffee mugs have numbers on ...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.088455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oh. That’s so Monica can keep track. That way ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.154864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Come on, Lydia, you can do it.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.132571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Push 'em out, push 'em out, way out!</td>\n",
       "      <td>joy</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.002250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Let's get that ball and really move, hey, hey,...</td>\n",
       "      <td>joy</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.023000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Utterance   Emotion Sentiment  \\\n",
       "0  Why do all you’re coffee mugs have numbers on ...  surprise  positive   \n",
       "1  Oh. That’s so Monica can keep track. That way ...     anger  negative   \n",
       "2                     Come on, Lydia, you can do it.   neutral   neutral   \n",
       "3               Push 'em out, push 'em out, way out!       joy  positive   \n",
       "4  Let's get that ball and really move, hey, hey,...       joy  positive   \n",
       "\n",
       "    Arousal  \n",
       "0 -0.088455  \n",
       "1 -0.154864  \n",
       "2 -0.132571  \n",
       "3 -0.002250  \n",
       "4 -0.023000  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"ar_-1-0.csv\") \n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae599827-fd22-40a1-a16c-5c9a8ff69aba",
   "metadata": {},
   "source": [
    "### Dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "61e890bf-2d15-4c66-b233-36bda8ce962e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    44728.000000\n",
       "mean         0.053255\n",
       "std          0.439983\n",
       "min         -1.000000\n",
       "25%         -0.272000\n",
       "50%          0.020000\n",
       "75%          0.404000\n",
       "max          1.000000\n",
       "Name: dominance, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dominance = pd.read_csv(\"VAD_lexicon/dominance.txt\", sep=\"\\t\",) \n",
    "dominance[\"dominance\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dcd3dfc6-40f9-4fb3-b60b-40f83db01c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dom(str):\n",
    "    words = str.split(\" \")\n",
    "    dom_score = 0\n",
    "    for word in words:\n",
    "        word = word.lower() # making the case the same to increase the chances of running into the word\n",
    "        word = word.translate(str.maketrans('', '', string.punctuation)) #removing punctuation \n",
    "        if word not in dom_cache.keys():\n",
    "            word_dom = dominance.loc[dominance[\"term\"] == word, \"dominance\"]\n",
    "            if len(word_dom) > 0:\n",
    "                score = word_dom.values[0]\n",
    "                dom_cache[word] = score  # Cache the result\n",
    "                dom_score += score\n",
    "            else:\n",
    "                lemma = lemmatizer.lemmatize(word)\n",
    "                if lemma != word:  # sometimes the word and the lemma are the same, \n",
    "                                         # in which case there isnt really a point in wasting time on the\n",
    "                    if lemma in dom_cache.keys():\n",
    "                        dom_score += dom_cache[lemma]\n",
    "                    else:\n",
    "                        lemma_dom = dominance.loc[dominance[\"term\"] == lemma, \"dominance\"]\n",
    "                        if len(lemma_dom) > 0:\n",
    "                            score = lemma_dom.values[0]\n",
    "                            dom_cache[lemma] = score  \n",
    "                            dom_score += score\n",
    "                        else:\n",
    "                            dom_cache[word] = 0\n",
    "        else:\n",
    "            dom_score += dom_cache[word]\n",
    "\n",
    "    return dom_score / len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fbd54157-d5e6-4e89-8356-f278b710baac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: dom_0-1.csv\n",
      "Created: dom_-1-0.csv\n"
     ]
    }
   ],
   "source": [
    "ranges = [\"0-1\", \"-1-0\"]\n",
    "\n",
    "# Ensure the folder exists\n",
    "# os.makedirs(\"Dominance\", exist_ok=True)\n",
    "\n",
    "for r in ranges:\n",
    "    file_path = f\"dom_{r}.csv\"\n",
    "    val = get_val\n",
    "    # Only create the file if it doesn't already exist\n",
    "    if not os.path.exists(file_path):\n",
    "        # Create a basic DataFrame structure\n",
    "        df = pd.DataFrame(columns=[\"Utterance\", \"Emotion\", \"Sentiment\", \"Dominance\"])\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"Created: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Already exists: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3d1fe6e8-7ae2-462b-8f69-3de566cf36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dialogues.iterrows():\n",
    "    dom = get_dom(row[\"Utterance\"])\n",
    "    new_row = [row[\"Utterance\"], row[\"Emotion\"], row[\"Sentiment\"], dom]\n",
    "    \n",
    "    d_cat = \"\"\n",
    "    \n",
    "    if dom > 0.0:\n",
    "        d_cat = \"0-1\"\n",
    "    else:\n",
    "        d_cat = \"-1-0\"\n",
    "    \n",
    "    fname = \"dom_\" + d_cat + \".csv\"\n",
    "    with open(fname, \"a\", newline=\"\") as f:  \n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1f33ee00-f34f-464d-bfb8-9258fc449740",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in ranges:\n",
    "    fname = \"dom_\" + r + \".csv\"\n",
    "    df = pd.read_csv(fname)\n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    df_cleaned.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "39ff6fb9-444b-4819-9422-6d72306f325a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Come on, Lydia, you can do it.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.021714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Push!</td>\n",
       "      <td>joy</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Push 'em out, push 'em out, harder, harder.</td>\n",
       "      <td>joy</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let's—  I was just—yeah, right.</td>\n",
       "      <td>joy</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ross, didn't you say that there was an elevato...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.041727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Utterance  Emotion Sentiment  \\\n",
       "0                     Come on, Lydia, you can do it.  neutral   neutral   \n",
       "1                                              Push!      joy  positive   \n",
       "2        Push 'em out, push 'em out, harder, harder.      joy  positive   \n",
       "3                    Let's—  I was just—yeah, right.      joy  positive   \n",
       "4  Ross, didn't you say that there was an elevato...  neutral   neutral   \n",
       "\n",
       "   Dominance  \n",
       "0   0.021714  \n",
       "1   0.048000  \n",
       "2   0.003500  \n",
       "3   0.070000  \n",
       "4   0.041727  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"dom_0-1.csv\") \n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909008a-6d4c-4754-b77f-2888d96a27d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a7fd4-cde4-4c43-a359-62bf96cadb7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56505572-14bd-4e64-9dbf-925b18d57ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (151B)",
   "language": "python",
   "name": "151b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
